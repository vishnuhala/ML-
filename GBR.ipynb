{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kO_f-M3IUr_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c71c62-435f-4c69-9673-d31555e3d9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Metrics:\n",
            "MSE scores for each fold: [0.1696674658683861, 0.1669805218789437, 0.20196922282223534, 0.17114507781120517, 0.16384988497534103, 0.1896200554742468, 0.14911592862894651, 0.18251846144226644, 0.1724747867481165, 0.1776755916346666]\n",
            "Average MSE: 0.17450169972843543\n",
            "Standard Deviation of MSE: 0.013822385161781449\n",
            "\n",
            "RMSE scores for each fold: [0.41190710830038624, 0.40863250223023584, 0.4494098606197191, 0.41369684288281094, 0.40478375087859075, 0.4354538499935978, 0.3861553167171812, 0.42722179420327616, 0.41530083884831787, 0.4215158260785312]\n",
            "Average RMSE: 0.41740776907526467\n",
            "Standard Deviation of RMSE: 0.01650618199481346\n",
            "\n",
            "R2 scores for each fold: [0.9540019352293204, 0.953993013136911, 0.943919538660406, 0.9536600721201043, 0.9562561930445139, 0.947964856487976, 0.9593466169529085, 0.9503579477875352, 0.952633511923874, 0.9514507087626743]\n",
            "Average R2: 0.9523584394106225\n",
            "Standard Deviation of R2: 0.004080618697662833\n",
            "\n",
            "MAPE scores for each fold: [2.9325741608797936e+16, 2.9548766300963612e+16, 3.448520091414977e+16, 2.767579912579995e+16, 2.939435030896157e+16, 3.2175803440200124e+16, 2.6292547168154944e+16, 2.919224098395382e+16, 3.182699686954083e+16, 3.029086230320321e+16]\n",
            "Average MAPE: 3.0020830902372576e+16\n",
            "Standard Deviation of MAPE: 2215715812914107.0\n",
            "\n",
            "Test Set Metrics:\n",
            "MSE: 1.4925964961198388\n",
            "RMSE: 1.2217186648815015\n",
            "R2: 0.5459700631774387\n",
            "MAPE: 9.85297938303098e+16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/Mathbert (1).xlsx')\n",
        "\n",
        "# Assume your dataset has all the embeddings as features and 'putting marks' as the target\n",
        "X = df.drop(columns=['putting marks'])  # Features\n",
        "y = df['putting marks']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Set up k-fold cross-validation\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "mse_scores_train = []\n",
        "rmse_scores_train = []\n",
        "r2_scores_train = []\n",
        "mape_scores_train = []\n",
        "\n",
        "mse_scores_test = []\n",
        "rmse_scores_test = []\n",
        "r2_scores_test = []\n",
        "mape_scores_test = []\n",
        "\n",
        "# Perform k-fold cross-validation manually to compute metrics\n",
        "for train_index, test_index in kf.split(X_train_full_scaled):\n",
        "    X_train_fold, X_test_fold = X_train_full_scaled[train_index], X_train_full_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y_train_full.iloc[train_index], y_train_full.iloc[test_index]\n",
        "\n",
        "    # Fit the Gradient Boosting model on the training fold\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the training set and test set\n",
        "    y_train_pred = model.predict(X_train_fold)\n",
        "    y_test_pred = model.predict(X_test_fold)\n",
        "\n",
        "    # Calculate metrics for training set\n",
        "    mse_train = mean_squared_error(y_train_fold, y_train_pred)\n",
        "    rmse_train = np.sqrt(mse_train)\n",
        "    r2_train = r2_score(y_train_fold, y_train_pred)\n",
        "    mape_train = mean_absolute_percentage_error(y_train_fold, y_train_pred) * 100\n",
        "\n",
        "    # Calculate metrics for test set\n",
        "    mse_test = mean_squared_error(y_test, model.predict(X_test_scaled))\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test, model.predict(X_test_scaled))\n",
        "    mape_test = mean_absolute_percentage_error(y_test, model.predict(X_test_scaled)) * 100\n",
        "\n",
        "    # Store the metrics\n",
        "    mse_scores_train.append(mse_train)\n",
        "    rmse_scores_train.append(rmse_train)\n",
        "    r2_scores_train.append(r2_train)\n",
        "    mape_scores_train.append(mape_train)\n",
        "\n",
        "    mse_scores_test.append(mse_test)\n",
        "    rmse_scores_test.append(rmse_test)\n",
        "    r2_scores_test.append(r2_test)\n",
        "    mape_scores_test.append(mape_test)\n",
        "\n",
        "# Print the metrics for training folds\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"MSE scores for each fold: {mse_scores_train}\")\n",
        "print(f\"Average MSE: {np.mean(mse_scores_train)}\")\n",
        "print(f\"Standard Deviation of MSE: {np.std(mse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"RMSE scores for each fold: {rmse_scores_train}\")\n",
        "print(f\"Average RMSE: {np.mean(rmse_scores_train)}\")\n",
        "print(f\"Standard Deviation of RMSE: {np.std(rmse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"R2 scores for each fold: {r2_scores_train}\")\n",
        "print(f\"Average R2: {np.mean(r2_scores_train)}\")\n",
        "print(f\"Standard Deviation of R2: {np.std(r2_scores_train)}\\n\")\n",
        "\n",
        "print(f\"MAPE scores for each fold: {mape_scores_train}\")\n",
        "print(f\"Average MAPE: {np.mean(mape_scores_train)}\")\n",
        "print(f\"Standard Deviation of MAPE: {np.std(mape_scores_train)}\\n\")\n",
        "\n",
        "# Print the metrics for the test set\n",
        "print(\"Test Set Metrics:\")\n",
        "print(f\"MSE: {mse_scores_test[-1]}\")\n",
        "print(f\"RMSE: {rmse_scores_test[-1]}\")\n",
        "print(f\"R2: {r2_scores_test[-1]}\")\n",
        "print(f\"MAPE: {mape_scores_test[-1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/Codebert (1).xlsx')\n",
        "\n",
        "# Assume your dataset has all the embeddings as features and 'putting marks' as the target\n",
        "X = df.drop(columns=['putting marks'])  # Features\n",
        "y = df['putting marks']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Set up k-fold cross-validation\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "mse_scores_train = []\n",
        "rmse_scores_train = []\n",
        "r2_scores_train = []\n",
        "mape_scores_train = []\n",
        "\n",
        "mse_scores_test = []\n",
        "rmse_scores_test = []\n",
        "r2_scores_test = []\n",
        "mape_scores_test = []\n",
        "\n",
        "# Perform k-fold cross-validation manually to compute metrics\n",
        "for train_index, test_index in kf.split(X_train_full_scaled):\n",
        "    X_train_fold, X_test_fold = X_train_full_scaled[train_index], X_train_full_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y_train_full.iloc[train_index], y_train_full.iloc[test_index]\n",
        "\n",
        "    # Fit the Gradient Boosting model on the training fold\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the training set and test set\n",
        "    y_train_pred = model.predict(X_train_fold)\n",
        "    y_test_pred = model.predict(X_test_fold)\n",
        "\n",
        "    # Calculate metrics for training set\n",
        "    mse_train = mean_squared_error(y_train_fold, y_train_pred)\n",
        "    rmse_train = np.sqrt(mse_train)\n",
        "    r2_train = r2_score(y_train_fold, y_train_pred)\n",
        "    mape_train = mean_absolute_percentage_error(y_train_fold, y_train_pred) * 100\n",
        "\n",
        "    # Calculate metrics for test set\n",
        "    mse_test = mean_squared_error(y_test, model.predict(X_test_scaled))\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test, model.predict(X_test_scaled))\n",
        "    mape_test = mean_absolute_percentage_error(y_test, model.predict(X_test_scaled)) * 100\n",
        "\n",
        "    # Store the metrics\n",
        "    mse_scores_train.append(mse_train)\n",
        "    rmse_scores_train.append(rmse_train)\n",
        "    r2_scores_train.append(r2_train)\n",
        "    mape_scores_train.append(mape_train)\n",
        "\n",
        "    mse_scores_test.append(mse_test)\n",
        "    rmse_scores_test.append(rmse_test)\n",
        "    r2_scores_test.append(r2_test)\n",
        "    mape_scores_test.append(mape_test)\n",
        "\n",
        "# Print the metrics for training folds\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"MSE scores for each fold: {mse_scores_train}\")\n",
        "print(f\"Average MSE: {np.mean(mse_scores_train)}\")\n",
        "print(f\"Standard Deviation of MSE: {np.std(mse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"RMSE scores for each fold: {rmse_scores_train}\")\n",
        "print(f\"Average RMSE: {np.mean(rmse_scores_train)}\")\n",
        "print(f\"Standard Deviation of RMSE: {np.std(rmse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"R2 scores for each fold: {r2_scores_train}\")\n",
        "print(f\"Average R2: {np.mean(r2_scores_train)}\")\n",
        "print(f\"Standard Deviation of R2: {np.std(r2_scores_train)}\\n\")\n",
        "\n",
        "print(f\"MAPE scores for each fold: {mape_scores_train}\")\n",
        "print(f\"Average MAPE: {np.mean(mape_scores_train)}\")\n",
        "print(f\"Standard Deviation of MAPE: {np.std(mape_scores_train)}\\n\")\n",
        "\n",
        "# Print the metrics for the test set\n",
        "print(\"Test Set Metrics:\")\n",
        "print(f\"MSE: {mse_scores_test[-1]}\")\n",
        "print(f\"RMSE: {rmse_scores_test[-1]}\")\n",
        "print(f\"R2: {r2_scores_test[-1]}\")\n",
        "print(f\"MAPE: {mape_scores_test[-1]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQHnwHXReOoA",
        "outputId": "d3cf76d9-0c83-487f-8049-a48204f13d8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Metrics:\n",
            "MSE scores for each fold: [0.15904549979698232, 0.1673228898610105, 0.1913634816379817, 0.1802277952106982, 0.15847890542125748, 0.18511063687368032, 0.1585136151538357, 0.18651086780377332, 0.1626022041457808, 0.1763707263483753]\n",
            "Average MSE: 0.17255466222533758\n",
            "Standard Deviation of MSE: 0.012181286640999406\n",
            "\n",
            "RMSE scores for each fold: [0.3988050899837944, 0.40905120689347746, 0.4374511191413067, 0.4245324430602427, 0.3980940911659673, 0.43024485688231107, 0.3981376836646284, 0.43186904010796295, 0.40323963612941227, 0.41996514896878684]\n",
            "Average RMSE: 0.41513903159978904\n",
            "Standard Deviation of RMSE: 0.014637167339583063\n",
            "\n",
            "R2 scores for each fold: [0.9568816262817194, 0.9538986828576901, 0.9468644173411779, 0.9512007991183398, 0.9576901097836746, 0.9492023218154141, 0.9567845315099544, 0.9492720782076298, 0.9553448042520508, 0.9518072590587887]\n",
            "Average R2: 0.9528946630226439\n",
            "Standard Deviation of R2: 0.003580593526319406\n",
            "\n",
            "MAPE scores for each fold: [2.8353498292093436e+16, 2.917607876651343e+16, 3.3410708979103864e+16, 2.9775758530958412e+16, 2.803629281891899e+16, 3.1612317609416332e+16, 2.879087844220519e+16, 3.195657327346581e+16, 3.0774643054882264e+16, 3.102339626929689e+16]\n",
            "Average MAPE: 3.029101460368546e+16\n",
            "Standard Deviation of MAPE: 1661909104711834.8\n",
            "\n",
            "Test Set Metrics:\n",
            "MSE: 1.6772250405174163\n",
            "RMSE: 1.295077233417921\n",
            "R2: 0.4898082762736168\n",
            "MAPE: 1.1716252149890595e+17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/drive/MyDrive/T5.xlsx')\n",
        "\n",
        "# Assume your dataset has all the embeddings as features and 'putting marks' as the target\n",
        "X = df.drop(columns=['putting marks'])  # Features\n",
        "y = df['putting marks']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Set up k-fold cross-validation\n",
        "k = 10\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "mse_scores_train = []\n",
        "rmse_scores_train = []\n",
        "r2_scores_train = []\n",
        "mape_scores_train = []\n",
        "\n",
        "mse_scores_test = []\n",
        "rmse_scores_test = []\n",
        "r2_scores_test = []\n",
        "mape_scores_test = []\n",
        "\n",
        "# Perform k-fold cross-validation manually to compute metrics\n",
        "for train_index, test_index in kf.split(X_train_full_scaled):\n",
        "    X_train_fold, X_test_fold = X_train_full_scaled[train_index], X_train_full_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y_train_full.iloc[train_index], y_train_full.iloc[test_index]\n",
        "\n",
        "    # Fit the Gradient Boosting model on the training fold\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the training set and test set\n",
        "    y_train_pred = model.predict(X_train_fold)\n",
        "    y_test_pred = model.predict(X_test_fold)\n",
        "\n",
        "    # Calculate metrics for training set\n",
        "    mse_train = mean_squared_error(y_train_fold, y_train_pred)\n",
        "    rmse_train = np.sqrt(mse_train)\n",
        "    r2_train = r2_score(y_train_fold, y_train_pred)\n",
        "    mape_train = mean_absolute_percentage_error(y_train_fold, y_train_pred) * 100\n",
        "\n",
        "    # Calculate metrics for test set\n",
        "    mse_test = mean_squared_error(y_test, model.predict(X_test_scaled))\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test, model.predict(X_test_scaled))\n",
        "    mape_test = mean_absolute_percentage_error(y_test, model.predict(X_test_scaled)) * 100\n",
        "\n",
        "    # Store the metrics\n",
        "    mse_scores_train.append(mse_train)\n",
        "    rmse_scores_train.append(rmse_train)\n",
        "    r2_scores_train.append(r2_train)\n",
        "    mape_scores_train.append(mape_train)\n",
        "\n",
        "    mse_scores_test.append(mse_test)\n",
        "    rmse_scores_test.append(rmse_test)\n",
        "    r2_scores_test.append(r2_test)\n",
        "    mape_scores_test.append(mape_test)\n",
        "\n",
        "# Print the metrics for training folds\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"MSE scores for each fold: {mse_scores_train}\")\n",
        "print(f\"Average MSE: {np.mean(mse_scores_train)}\")\n",
        "print(f\"Standard Deviation of MSE: {np.std(mse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"RMSE scores for each fold: {rmse_scores_train}\")\n",
        "print(f\"Average RMSE: {np.mean(rmse_scores_train)}\")\n",
        "print(f\"Standard Deviation of RMSE: {np.std(rmse_scores_train)}\\n\")\n",
        "\n",
        "print(f\"R2 scores for each fold: {r2_scores_train}\")\n",
        "print(f\"Average R2: {np.mean(r2_scores_train)}\")\n",
        "print(f\"Standard Deviation of R2: {np.std(r2_scores_train)}\\n\")\n",
        "\n",
        "print(f\"MAPE scores for each fold: {mape_scores_train}\")\n",
        "print(f\"Average MAPE: {np.mean(mape_scores_train)}\")\n",
        "print(f\"Standard Deviation of MAPE: {np.std(mape_scores_train)}\\n\")\n",
        "\n",
        "# Print the metrics for the test set\n",
        "print(\"Test Set Metrics:\")\n",
        "print(f\"MSE: {mse_scores_test[-1]}\")\n",
        "print(f\"RMSE: {rmse_scores_test[-1]}\")\n",
        "print(f\"R2: {r2_scores_test[-1]}\")\n",
        "print(f\"MAPE: {mape_scores_test[-1]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72UNmmWWfqf0",
        "outputId": "0e47aae2-e068-42e1-e23e-10139d59e10f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Metrics:\n",
            "MSE scores for each fold: [0.17841163956750616, 0.2101339532174764, 0.19549727506136855, 0.21571766509174617, 0.19607361066487997, 0.2278686857669623, 0.1859783782318628, 0.22355517205755254, 0.2111420094324182, 0.2093979046341578]\n",
            "Average MSE: 0.20537762937259307\n",
            "Standard Deviation of MSE: 0.015175249711486895\n",
            "\n",
            "RMSE scores for each fold: [0.4223880201515026, 0.4584037011385013, 0.44215073794054505, 0.46445415822419567, 0.44280199939124026, 0.477355931949067, 0.4312521051912243, 0.4728162138268447, 0.4595019145035396, 0.4576001580355472]\n",
            "Average RMSE: 0.4528724940352208\n",
            "Standard Deviation of RMSE: 0.016856260525751683\n",
            "\n",
            "R2 scores for each fold: [0.9516313271335397, 0.9421032470351592, 0.9457165937320821, 0.9415914195686174, 0.9476532670420827, 0.9374687464565657, 0.9492968302028258, 0.9391966301055087, 0.9420143914324385, 0.942782687464056]\n",
            "Average R2: 0.9439455140172877\n",
            "Standard Deviation of R2: 0.004279135295887209\n",
            "\n",
            "MAPE scores for each fold: [3.3817433942792024e+16, 3.71673243478778e+16, 3.700314587804842e+16, 3.798561854869663e+16, 3.5438149376093736e+16, 3.899061413978162e+16, 3.4387327696148732e+16, 4.011471526186122e+16, 3.810537822660911e+16, 3.796006532483044e+16]\n",
            "Average MAPE: 3.7096977274273976e+16\n",
            "Standard Deviation of MAPE: 1900188102667558.5\n",
            "\n",
            "Test Set Metrics:\n",
            "MSE: 1.7111186242575893\n",
            "RMSE: 1.3080973298105876\n",
            "R2: 0.4794982549622673\n",
            "MAPE: 1.0620205704466365e+17\n",
            "\n"
          ]
        }
      ]
    }
  ]
}