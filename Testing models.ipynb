{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMLNHvDi4rsK",
        "outputId": "bad0a9aa-94a7-4eae-90d9-335788aa2ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - RMSE: 0.017503546989144043, R²: 0.9998\n",
            "Ridge Regression - RMSE: 0.3099869029135285, R²: 0.9331\n",
            "Lasso Regression - RMSE: 0.6158453894516058, R²: 0.7359\n",
            "ElasticNet - RMSE: 0.4761261830754729, R²: 0.8421\n",
            "Polynomial Regression - RMSE: 0.017506990189741334, R²: 0.9998\n",
            "SVM - RMSE: 0.4302788758837052, R²: 0.8711\n",
            "KNN Regressor - RMSE: 0.6719561402846401, R²: 0.6856\n",
            "Decision Tree - RMSE: 0.39622002617799507, R²: 0.8907\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVR  # Support Vector Regressor\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/Codebert test.xlsx\"\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(fit_intercept= True),\n",
        "    \"Ridge Regression\": Ridge(alpha=100,solver='saga'),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"Polynomial Regression\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
        "    \"SVM\": SVR(kernel='rbf', C=100, epsilon=0.5),\n",
        "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=3, weights='uniform'),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, min_samples_leaf=2, min_samples_split=10),\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:}, R²: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVR  # Support Vector Regressor\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/Mathbert test.xlsx\"\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(fit_intercept= False),\n",
        "    \"Ridge Regression\": Ridge(alpha=100, solver='saga'),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"Polynomial Regression\": make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=0.1)),\n",
        "    \"SVM\": SVR(kernel='rbf', C=100, epsilon=0.5),\n",
        "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=3,p=1, weights='uniform'),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, min_samples_leaf=4, min_samples_split=10),\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:}, R²: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "pn6aX3P28UIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8cbe7e-7c6e-4103-cbf5-eefb09e64d36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - RMSE: 3.931269979815481, R²: -9.7629\n",
            "Ridge Regression - RMSE: 0.19745010183449213, R²: 0.9728\n",
            "Lasso Regression - RMSE: 0.47777322849867204, R²: 0.8410\n",
            "ElasticNet - RMSE: 0.3363660607977755, R²: 0.9212\n",
            "Polynomial Regression - RMSE: 0.2637026278941464, R²: 0.9516\n",
            "SVM - RMSE: 0.4177642023694111, R²: 0.8785\n",
            "KNN Regressor - RMSE: 0.6916774942061404, R²: 0.6668\n",
            "Decision Tree - RMSE: 0.3573260236098106, R²: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVR  # Support Vector Regressor\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/Codebert test.xlsx\"\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(fit_intercept= True),\n",
        "    \"Ridge Regression\": Ridge(alpha=100, solver='saga'),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"Polynomial Regression\": make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=0.1)),\n",
        "    \"SVM\": SVR(kernel='rbf', C=10, epsilon=0.5),\n",
        "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=3,p=1, weights='uniform'),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, min_samples_leaf=2, min_samples_split=10),\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:}, R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9jshwfY8tTH",
        "outputId": "95fc0a17-e244-4386-c8e4-32f977e5bca9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - RMSE: 0.017503546989144043, R²: 0.9998\n",
            "Ridge Regression - RMSE: 0.31004066927331764, R²: 0.9331\n",
            "Lasso Regression - RMSE: 0.6158453894516058, R²: 0.7359\n",
            "ElasticNet - RMSE: 0.4761261830754729, R²: 0.8421\n",
            "Polynomial Regression - RMSE: 0.33631270106186717, R²: 0.9212\n",
            "SVM - RMSE: 0.4302788758837052, R²: 0.8711\n",
            "KNN Regressor - RMSE: 0.6653377277285557, R²: 0.6917\n",
            "Decision Tree - RMSE: 0.39622002617799507, R²: 0.8907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVR  # Support Vector Regressor\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/T5 test.xlsx\"\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(fit_intercept= False),\n",
        "    \"Ridge Regression\": Ridge(alpha=100, solver='saga'),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"Polynomial Regression\": make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=0.1)),\n",
        "    \"SVM\": SVR(kernel='rbf', C=10, epsilon=0.5),\n",
        "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=11,p=1, weights='distance'),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, min_samples_leaf=4, min_samples_split=2),\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:}, R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU_muNbe8xU2",
        "outputId": "a362f1ac-b776-4df9-d0fb-1be41ab5797f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - RMSE: 3.824839498523273, R²: -9.1880\n",
            "Ridge Regression - RMSE: 0.2515210992137939, R²: 0.9559\n",
            "Lasso Regression - RMSE: 0.5312515211080925, R²: 0.8035\n",
            "ElasticNet - RMSE: 0.41316077009784113, R²: 0.8811\n",
            "Polynomial Regression - RMSE: 0.3012644001744052, R²: 0.9368\n",
            "SVM - RMSE: 0.43801026059029935, R²: 0.8664\n",
            "KNN Regressor - RMSE: 0.020211302086361082, R²: 0.9997\n",
            "Decision Tree - RMSE: 0.34099174447051, R²: 0.9190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/Mathbert test.xlsx\"  # Update the path to your file\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=200, learning_rate=0.1, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, objective='reg:squarederror')\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exEVl2tzA2oq",
        "outputId": "85fdd985-ec97-47bd-f8c5-6eed362ef277"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - RMSE: 0.2873, R²: 0.9425\n",
            "Gradient Boosting - RMSE: 0.0208, R²: 0.9997\n",
            "AdaBoost - RMSE: 0.2215, R²: 0.9658\n",
            "XGBoost - RMSE: 0.0203, R²: 0.9997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/Codebert test.xlsx\"  # Update the path to your file\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=200, learning_rate=0.1, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, objective='reg:squarederror')\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDaMq3XXCulX",
        "outputId": "77eda461-c992-40cd-8daa-3d17f06edaf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - RMSE: 0.3360, R²: 0.9214\n",
            "Gradient Boosting - RMSE: 0.0180, R²: 0.9998\n",
            "AdaBoost - RMSE: 0.2869, R²: 0.9427\n",
            "XGBoost - RMSE: 0.0189, R²: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute metrics\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# Load the test data\n",
        "file_path = r\"/content/T5 test.xlsx\"  # Update the path to your file\n",
        "test_data = pd.read_excel(file_path)\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Replace synthetic data with real training data if available\n",
        "# Simulate with a subset of the test data for demonstration\n",
        "X_train = X_test.copy()\n",
        "y_train = y_test.copy()\n",
        "\n",
        "# Scale features to ensure consistency\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=200, learning_rate=0.1, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, objective='reg:squarederror')\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    rmse, r2 = test_metrics(model, X_test_scaled, y_test)\n",
        "    print(f\"{name} - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBtHCeF3DCE3",
        "outputId": "70ee528d-3102-4c09-b1ab-0d1159554809"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - RMSE: 0.2956, R²: 0.9392\n",
            "Gradient Boosting - RMSE: 0.0214, R²: 0.9997\n",
            "AdaBoost - RMSE: 0.2404, R²: 0.9598\n",
            "XGBoost - RMSE: 0.0229, R²: 0.9996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKw3OgY1DSIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}